{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch \n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error, r2_score, f1_score\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.svm import SVR, SVC\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.device(0)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_Loader(data.Dataset):\n",
    "    def __init__(self, data_path, files, labels,  transform=None):\n",
    "        self.data_path = data_path\n",
    "        self.labels = labels\n",
    "        self.files = files\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def read_image(self, path, selected_file, use_transform):\n",
    "        filename = path+selected_file+\"/frame1.jpg\"       \n",
    "        image = Image.open(filename)      \n",
    "        if use_transform is not None:\n",
    "            image = use_transform(image)\n",
    "        return image\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X = self.read_image(self.data_path, self.files[index][:-4], self.transform)\n",
    "        y = torch.FloatTensor(self.labels[index])\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D CNN model using VGG-19 pretrained\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, out= 6, fc_hidden1= 512, fc_hidden2=64, pretrained=True):\n",
    "        super(CNNModel, self).__init__()\n",
    "        \n",
    "        self.vgg19 = models.vgg19(pretrained=pretrained)\n",
    "        num_features = self.vgg19.classifier[6].in_features\n",
    "        modules = list(self.vgg19.classifier.children())[:-1] # Remove last layer\n",
    "\n",
    "        modules.extend([nn.Linear(num_features, fc_hidden1)]) \n",
    "        modules.extend([nn.ReLU(inplace=True)]) \n",
    "        modules.extend([nn.Linear(fc_hidden1, fc_hidden2)]) \n",
    "        modules.extend([nn.ReLU(inplace=True)]) \n",
    "        modules.extend([nn.Linear(fc_hidden2, out)]) \n",
    "        \n",
    "        self.vgg19.classifier = nn.Sequential(*modules) # Replace the model classifier\n",
    "        \n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x_inp):\n",
    "        \n",
    "        x = self.vgg19(x_inp) \n",
    "        x = self.sigmoid(x)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Path\n",
    "training_data_path = \"/home/ramsub/first-impressions/data/image_data/training_data/\"    \n",
    "validation_data_path = \"/home/ramsub/first-impressions/data/image_data/validation_data/\"\n",
    "test_data_path = \"/home/ramsub/first-impressions/data/image_data/test_data/\"\n",
    "save_model_path = \"./saved_models/\"\n",
    "\n",
    "#Read CSV files\n",
    "aud_train = pd.read_csv('../audio/pickle_files/training_df_all.csv')\n",
    "aud_test = pd.read_csv('../audio/pickle_files/test_df_all.csv')\n",
    "aud_val = pd.read_csv('../audio/pickle_files/validation_df_all.csv')\n",
    "\n",
    "labels = ['interview_score', 'openness', 'conscientiousness', 'extraversion', 'agreeableness', 'neuroticism']\n",
    "\n",
    "train_label = aud_train[labels].values\n",
    "train_list = aud_train['video_id'].values\n",
    "\n",
    "test_label = aud_test[labels].values\n",
    "test_list = aud_test['video_id'].values\n",
    "\n",
    "val_label = aud_val[labels].values\n",
    "val_list = aud_val['video_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Function\n",
    "def train(model, device, train_loader, optimizer, epoch, log_interval):\n",
    "    model.train()\n",
    "\n",
    "    losses = []\n",
    "    N_count = 0 \n",
    "    for batch_idx, (X, y) in enumerate(train_loader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        N_count += X.size(0)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X) \n",
    "        \n",
    "        criterion = nn.MSELoss(reduction = 'sum')\n",
    "        loss = criterion(output, y)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (batch_idx + 1) % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\t\\tLoss: {:.6f}'.format(\n",
    "                epoch + 1, N_count, len(train_loader.dataset), 100. * (batch_idx + 1) / len(train_loader), loss.item()))\n",
    "\n",
    "    return losses\n",
    "\n",
    "# Evaluation Function\n",
    "def evaluation(model, device, loader):\n",
    "    model.eval()\n",
    "    \n",
    "    loss = 0\n",
    "    all_y = []\n",
    "    all_y_pred = []\n",
    "    score = []\n",
    "    with torch.no_grad():\n",
    "        for (X, y) in loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            output = model(X)\n",
    "            \n",
    "            criterion = nn.MSELoss(reduction = 'sum')\n",
    "            loss = criterion(output, y)\n",
    "            loss += loss.item() \n",
    "            \n",
    "            # collect all y and y_pred in all batches\n",
    "            all_y.extend(y.cpu().detach().numpy())\n",
    "            all_y_pred.extend(output.cpu().detach().numpy())\n",
    "\n",
    "    loss /= len(loader.dataset)\n",
    "    \n",
    "    all_y = np.asarray(all_y)\n",
    "    all_y_pred = np.asarray(all_y_pred)\n",
    "    \n",
    "    for i in range(all_y.shape[1]):\n",
    "        score.extend([1 - mean_absolute_error(all_y[:,i], all_y_pred[:,i])])\n",
    "\n",
    "    return loss.cpu().detach().numpy(), np.asarray(score), all_y, all_y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the CNN Model params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "img_size = 224\n",
    "epochs = 1\n",
    "batch_size = 64\n",
    "learning_rate = 1e-4\n",
    "l_decay = 5e-4\n",
    "log_interval = 10\n",
    "\n",
    "use_cuda = torch.cuda.is_available()                   # check if GPU exists\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")   # use CPU or GPU\n",
    "print(device)\n",
    "\n",
    "train_params = {'batch_size': batch_size, 'shuffle': True, 'num_workers': 0, 'pin_memory': True} if use_cuda else {}\n",
    "test_params = {'batch_size': batch_size, 'shuffle': False, 'num_workers': 0, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize([img_size, img_size]),\n",
    "                                transforms.RandomHorizontalFlip(),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = Dataset_Loader(training_data_path, train_list, train_label, transform=transform)\n",
    "train_loader = data.DataLoader(train_set, **train_params)\n",
    "\n",
    "val_set = Dataset_Loader(validation_data_path, val_list, val_label, transform=transform)\n",
    "val_loader = data.DataLoader(val_set, **test_params)\n",
    "\n",
    "test_set = Dataset_Loader(test_data_path, test_list, test_label, transform=transform)\n",
    "test_loader = data.DataLoader(test_set, **test_params)\n",
    "\n",
    "model = CNNModel().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "val_losses = []\n",
    "val_scores = []\n",
    "train_losses = []\n",
    "train_scores = []\n",
    "\n",
    "epoch_train_loss, epoch_train_score, train_annot, train_annot_pred = evaluation(model, device, train_loader)\n",
    "epoch_val_loss, epoch_val_score, test_annot, test_annot_pred = evaluation(model, device, val_loader)\n",
    "    \n",
    "train_losses.append(epoch_train_loss.tolist())    \n",
    "train_scores.append(epoch_train_score.tolist())\n",
    "val_losses.append(epoch_val_loss.tolist())    \n",
    "val_scores.append(epoch_val_score.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    train(model, device, train_loader, optimizer, epoch, log_interval)    \n",
    "    \n",
    "    epoch_train_loss, epoch_train_score, train_annot, train_annot_pred = evaluation(model, device, train_loader)\n",
    "    epoch_val_loss, epoch_val_score, test_annot, test_annot_pred = evaluation(model, device, val_loader)\n",
    "    \n",
    "    train_losses.append(epoch_train_loss.tolist())    \n",
    "    train_scores.append(epoch_train_score.tolist())\n",
    "    val_losses.append(epoch_val_loss.tolist())    \n",
    "    val_scores.append(epoch_val_score.tolist())\n",
    "\n",
    "    if min(val_losses) == epoch_val_loss:\n",
    "        torch.save(model.state_dict(), os.path.join(save_model_path, 'vgg_model_trained.pth'))\n",
    "\n",
    "np.save(save_model_path+'/train_score',train_scores)\n",
    "np.save(save_model_path+'/train_loss',train_losses)\n",
    "np.save(save_model_path+'/val_score',val_scores)\n",
    "np.save(save_model_path+'/val_loss',val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing loss: 0.0014462\n",
      " Interview: 0.9106\n",
      " openness: 0.9048\n",
      " conscientiousness: 0.9070\n",
      " extraversion: 0.9044\n",
      " agreeableness: 0.9078\n",
      " neuroticism: 0.9019\n"
     ]
    }
   ],
   "source": [
    "saved_model_t = CNNModel(out= 6, fc_hidden1= 512, fc_hidden2=64, pretrained=False).to(device)\n",
    "saved_model_t.load_state_dict(torch.load(os.path.join(save_model_path, 'vgg_model_trained.pth')))\n",
    "\n",
    "test_loss, test_score, test_annot, test_annot_pred = evaluation(saved_model_t, device, test_loader)\n",
    "print('\\nTesting loss: {:.7f}\\n Interview: {:.4f}\\n openness: {:.4f}\\n conscientiousness: {:.4f}\\n extraversion: {:.4f}\\n agreeableness: {:.4f}\\n neuroticism: {:.4f}'.format(test_loss, test_score[0],test_score[1],test_score[2],test_score[3],test_score[4],test_score[5]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
