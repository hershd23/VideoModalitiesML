{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "LRCN.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cz8SDahBX2kt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch \n",
        "print(torch.__version__)\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import torch.utils.data as data\n",
        "import torchvision\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "from ipywidgets import FloatProgress"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxwOvSQaX2lD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.device(1)\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqYnGJhoX2lY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Li6WyxOX2ln",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwJ2fWLJX2ly",
        "colab_type": "text"
      },
      "source": [
        "# IMAGE FUNCTIONS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UO8rGc1lX2l1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torch.utils import data\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WW6J3PB3X2mD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dataset_CRNN(data.Dataset):\n",
        "    \"Characterizes a dataset for PyTorch\"\n",
        "    def __init__(self, data_path, folders, labels, frames, transform=None):\n",
        "        \"Initialization\"\n",
        "        self.data_path = data_path\n",
        "        self.labels = labels\n",
        "        self.folders = folders\n",
        "        self.transform = transform\n",
        "        self.frames = frames\n",
        "        self.factor = 5\n",
        "\n",
        "    def __len__(self):\n",
        "        \"Denotes the total number of samples\"\n",
        "        return len(self.folders)\n",
        "\n",
        "    def read_images(self, path, selected_folder, use_transform):\n",
        "        X = []\n",
        "        \n",
        "        for i in range(20):\n",
        "            image = Image.open(Path(path, selected_folder, 'frame{}.jpg'.format(i+1)))\n",
        "            if use_transform is not None:\n",
        "                image = use_transform(image)\n",
        "\n",
        "            X.append(image)\n",
        "        \n",
        "        X = torch.stack(X, dim=0)\n",
        "\n",
        "        return X\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"Generates one sample of data\"\n",
        "        # Select sample\n",
        "        folder = self.folders[index]\n",
        "\n",
        "        # Load data\n",
        "        X = self.read_images(self.data_path, folder, self.transform)     # (input) spatial images\n",
        "        y = torch.FloatTensor(self.labels[index])\n",
        "\n",
        "        return X, y\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FawPOj-iX2mS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2D CNN encoder using ResNet-50 pretrained\n",
        "class ResCNNEncoder(nn.Module):\n",
        "    def __init__(self, fc_hidden1=512, fc_hidden2=512, drop_p=0.3, CNN_embed_dim=300):\n",
        "        \"\"\"Load the pretrained ResNet-152 and replace top fc layer.\"\"\"\n",
        "        super(ResCNNEncoder, self).__init__()\n",
        "\n",
        "        self.fc_hidden1, self.fc_hidden2 = fc_hidden1, fc_hidden2\n",
        "        self.drop_p = drop_p\n",
        "\n",
        "        resnet = models.resnet50(pretrained=True)\n",
        "        modules = list(resnet.children())[:-1]      # delete the last fc layer.\n",
        "        self.resnet = nn.Sequential(*modules)\n",
        "        self.fc1 = nn.Linear(resnet.fc.in_features, fc_hidden1)\n",
        "        self.bn1 = nn.BatchNorm1d(fc_hidden1, momentum=0.01)\n",
        "        self.fc2 = nn.Linear(fc_hidden1, fc_hidden2)\n",
        "        self.bn2 = nn.BatchNorm1d(fc_hidden2, momentum=0.01)\n",
        "        self.fc3 = nn.Linear(fc_hidden2, CNN_embed_dim)\n",
        "        \n",
        "    def forward(self, x_3d):\n",
        "        cnn_embed_seq = []\n",
        "        for t in range(x_3d.size(1)):\n",
        "            # ResNet CNN\n",
        "            with torch.no_grad():\n",
        "                x = self.resnet(x_3d[:, t, :, :, :])  # ResNet\n",
        "                x = x.view(x.size(0), -1)             # flatten output of conv\n",
        "\n",
        "            # FC layers\n",
        "            x = self.bn1(self.fc1(x))\n",
        "            x = F.relu(x)\n",
        "            x = self.bn2(self.fc2(x))\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.drop_p, training=self.training)\n",
        "            x = self.fc3(x)\n",
        "\n",
        "            cnn_embed_seq.append(x)\n",
        "\n",
        "        # swap time and sample dim such that (sample dim, time dim, CNN latent dim)\n",
        "        cnn_embed_seq = torch.stack(cnn_embed_seq, dim=0).transpose_(0, 1)\n",
        "        # cnn_embed_seq: shape=(batch, time_step, input_size)\n",
        "\n",
        "        return cnn_embed_seq\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFb1aKSlX2mb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, CNN_embed_dim=300, h_RNN_layers=3, h_RNN=256, h_FC_dim=128, drop_p=0.3, num_classes=50):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "\n",
        "        self.RNN_input_size = CNN_embed_dim\n",
        "        self.h_RNN_layers = h_RNN_layers   # RNN hidden layers\n",
        "        self.h_RNN = h_RNN                 # RNN hidden nodes\n",
        "        self.h_FC_dim = h_FC_dim\n",
        "        self.drop_p = drop_p\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.LSTM = nn.LSTM(\n",
        "            input_size=self.RNN_input_size,\n",
        "            hidden_size=self.h_RNN,        \n",
        "            num_layers=h_RNN_layers,       \n",
        "            batch_first=True,       # input & output will has batch size as 1s dimension. e.g. (batch, time_step, input_size)\n",
        "        )\n",
        "\n",
        "        self.fc1 = nn.Linear(self.h_RNN, self.h_FC_dim)\n",
        "        self.fc2 = nn.Linear(self.h_FC_dim, self.num_classes)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x_RNN):\n",
        "        \n",
        "        self.LSTM.flatten_parameters()\n",
        "        RNN_out, (h_n, h_c) = self.LSTM(x_RNN, None)  \n",
        "        \"\"\" h_n shape (n_layers, batch, hidden_size), h_c shape (n_layers, batch, hidden_size) \"\"\" \n",
        "        \"\"\" None represents zero initial hidden state. RNN_out has shape=(batch, time_step, output_size) \"\"\"\n",
        "\n",
        "        # FC layers\n",
        "        x = self.fc1(RNN_out[:, -1, :])   # choose RNN_out at the last time step\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.drop_p, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHOIyZA0X2mk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZcAi4lOX2mv",
        "colab_type": "text"
      },
      "source": [
        "# IMAGE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5XZ1f_kX2my",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set path\n",
        "training_data_path = \"\"       #\"../data/image_data/training_data/\"    # define UCF-101 RGB data path\n",
        "validation_data_path = \"\"\n",
        "test_data_path = \"\"\n",
        "save_model_path = \"./ResNetCRNN_ckpt/\"\n",
        "\n",
        "# EncoderCNN architecture\n",
        "CNN_fc_hidden1, CNN_fc_hidden2 = 1024, 768\n",
        "CNN_embed_dim = 512   # latent dim extracted by 2D CNN\n",
        "res_size = 224        # ResNet image size\n",
        "dropout_p = 0.25    # dropout probability\n",
        "\n",
        "# DecoderRNN architecture\n",
        "RNN_hidden_layers = 3\n",
        "RNN_hidden_nodes = 512\n",
        "RNN_FC_dim = 256\n",
        "\n",
        "# training parameters\n",
        "k = 6           # number of target category\n",
        "epochs = 50       # training epochs\n",
        "batch_size = 16*8\n",
        "learning_rate = 1e-5\n",
        "l_decay = 5e-4\n",
        "log_interval = 10  # interval for displaying training info\n",
        "\n",
        "# Select which frame to begin & end in videos\n",
        "begin_frame, end_frame, skip_frame = 1, 20, 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HxuEf4sX2m8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(log_interval, model, device, train_loader, optimizer, epoch):\n",
        "    # set model as training mode\n",
        "    cnn_encoder, rnn_decoder = model\n",
        "    cnn_encoder.train()\n",
        "    rnn_decoder.train()\n",
        "\n",
        "    train_loss = 0\n",
        "    scores = []\n",
        "    N_count = 0   # counting total trained sample in one epoch\n",
        "    for batch_idx, (X, y) in enumerate(train_loader):\n",
        "        # distribute data to device\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        \n",
        "        N_count += X.size(0)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = rnn_decoder(cnn_encoder(X))   # output has dim = (batch, number of classes)\n",
        "        \n",
        "        criterion = nn.L1Loss(reduction = 'sum')\n",
        "        loss = criterion(output, y)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # show information\n",
        "        if (batch_idx + 1) % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch + 1, N_count, len(train_loader.dataset), 100. * (batch_idx + 1) / len(train_loader), loss.item()))\n",
        "\n",
        "    \n",
        "    return train_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8OGE2u1X2nI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validation(model, device, optimizer, test_loader):\n",
        "    # set model as testing mode\n",
        "    cnn_encoder, rnn_decoder = model\n",
        "    cnn_encoder.eval()\n",
        "    rnn_decoder.eval()\n",
        "\n",
        "    test_loss = 0\n",
        "    all_y = []\n",
        "    all_y_pred = []\n",
        "    score = []\n",
        "    with torch.no_grad():\n",
        "        for (X, y) in test_loader:\n",
        "            # distribute data to device\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            output = rnn_decoder(cnn_encoder(X))   # output has dim = (batch, number of classes)\n",
        "            \n",
        "            criterion = nn.L1Loss(reduction = 'sum')\n",
        "            loss = criterion(output, y)\n",
        "            test_loss += loss.item()                 # sum up batch loss\n",
        "            \n",
        "            all_y.extend(y.cpu().detach().numpy())\n",
        "            all_y_pred.extend(output.cpu().detach().numpy())\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nValid set ({:d} samples): Average loss: {:.8f}, \\n'.format(len(all_y), test_loss))\n",
        "    \n",
        "    all_y = np.asarray(all_y)\n",
        "    all_y_pred = np.asarray(all_y_pred)\n",
        "    \n",
        "    for i in range(all_y.shape[1]):\n",
        "        score.extend([1 - mean_absolute_error(all_y[:,i], all_y_pred[:,i])])\n",
        "        \n",
        "    print('Validation scores' + str(score))\n",
        "\n",
        "    return test_loss, np.asarray(score)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQezqsD1X2nU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def CRNN_final_prediction(model, device, loader):\n",
        "    cnn_encoder, rnn_decoder = model\n",
        "    cnn_encoder.eval()\n",
        "    rnn_decoder.eval()\n",
        "\n",
        "    all_y_pred = []\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (X, y) in enumerate(tqdm(loader)):\n",
        "            # distribute data to device\n",
        "            X = X.to(device)\n",
        "            output = rnn_decoder(cnn_encoder(X))   # output has dim = (batch, number of classes)\n",
        "            #y_pred = output.max(1, keepdim=True)[1]  # location of max log-probability as prediction\n",
        "            all_y_pred.append(output)\n",
        "\n",
        "    return all_y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtI454DLX2nf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Detect devices\n",
        "use_cuda = torch.cuda.is_available()                   # check if GPU exists\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")   # use CPU or GPU\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvsbrQvjX2np",
        "colab_type": "text"
      },
      "source": [
        "## Image data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ko1PT7GVX2ns",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params = {'batch_size': batch_size, 'shuffle': True, 'num_workers': 0, 'pin_memory': True} if use_cuda else {}\n",
        "params2 = {'batch_size': batch_size, 'shuffle': False, 'num_workers': 0, 'pin_memory': True} if use_cuda else {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHGctJ5SX2n2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose([transforms.Resize([res_size, res_size]),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
        "\n",
        "selected_frames = np.arange(begin_frame, end_frame, skip_frame).tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10C_cRKUX2n-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#with open('../data/image_data/pickle_files/y_5d_training_all.pkl', 'rb') as file:\n",
        "#    train_label = pickle.load(file)\n",
        "\n",
        "#with open('../data/image_data/pickle_files/vid_ids_5d_training.pkl', 'rb') as file:\n",
        "#    train_list = pickle.load(file)\n",
        "    \n",
        "train_label_df = pd.read_csv('./training_path_labels.csv')\n",
        "train_list = train_label_df['path'].values.tolist()\n",
        "train_label = train_label_df[['o', 'c', 'e', 'a', 'n', 'i']].values\n",
        "\n",
        "valid_label_df = pd.read_csv('./validation_path_labels.csv')\n",
        "valid_list = valid_label_df['path'].values.tolist()\n",
        "valid_label = valid_label_df[['o', 'c', 'e', 'a', 'n', 'i']].values\n",
        "\n",
        "test_label_df = pd.read_csv('./test_path_labels.csv')\n",
        "test_list = test_label_df['path'].values.tolist()\n",
        "test_label = test_label_df[['o', 'c', 'e', 'a', 'n', 'i']].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8l_y5a0gX2oQ",
        "colab_type": "text"
      },
      "source": [
        "# Begin training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0St17_kX2oS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Return validation set back when values are returned\n",
        "train_set, valid_set = Dataset_CRNN(training_data_path, train_list, train_label, selected_frames, transform=transform), \\\n",
        "                       Dataset_CRNN(validation_data_path, valid_list, valid_label, selected_frames, transform=transform)\n",
        "\n",
        "train_loader = data.DataLoader(train_set, **params)\n",
        "valid_loader = data.DataLoader(valid_set, **params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ts2YOXkqX2oZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_set = Dataset_CRNN(test_data_path, test_list, test_label, selected_frames, transform=transform)\n",
        "test_loader = data.DataLoader(test_set, **params2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "yqPDgJaAX2oj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn_encoder = ResCNNEncoder(fc_hidden1=CNN_fc_hidden1, fc_hidden2=CNN_fc_hidden2, drop_p=dropout_p, CNN_embed_dim=CNN_embed_dim).to(device)\n",
        "rnn_decoder = DecoderRNN(CNN_embed_dim=CNN_embed_dim, h_RNN_layers=RNN_hidden_layers, h_RNN=RNN_hidden_nodes, \n",
        "                         h_FC_dim=RNN_FC_dim, drop_p=dropout_p, num_classes=k).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-UfMDSHX2ov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn_encoder.load_state_dict(torch.load(os.path.join(save_model_path, 'cnn_encoder_best.pth')))\n",
        "rnn_decoder.load_state_dict(torch.load(os.path.join(save_model_path, 'rnn_decoder_best.pth')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALWcxMIsX2o2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Using\", torch.cuda.device_count(), \"GPU!\")\n",
        "# Combine all EncoderCNN + DecoderRNN parameters\n",
        "crnn_params = list(cnn_encoder.fc1.parameters()) + list(cnn_encoder.bn1.parameters()) + \\\n",
        "              list(cnn_encoder.fc2.parameters()) + list(cnn_encoder.bn2.parameters()) + \\\n",
        "              list(cnn_encoder.fc3.parameters()) + list(rnn_decoder.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OzY91b2X2pB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = torch.optim.Adam(\n",
        "            [\n",
        "                {\"params\": cnn_encoder.resnet.parameters(), \"lr\": 1e-6},\n",
        "                {\"params\": crnn_params}\n",
        "            ],\n",
        "            lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-JbH_kdX2pI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epoch_train_losses = []\n",
        "epoch_valid_losses = []\n",
        "epoch_valid_scores = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "IFPJtaN-X2pP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(epochs):\n",
        "    # train, test model\n",
        "    if __name__ == '__main__':\n",
        "        train_loss = train(log_interval, [cnn_encoder, rnn_decoder], device, train_loader, optimizer, epoch)\n",
        "        valid_loss, valid_scores = validation([cnn_encoder, rnn_decoder], device, optimizer, valid_loader)\n",
        "\n",
        "    # save results\n",
        "    epoch_train_losses.append(train_loss)\n",
        "    epoch_valid_losses.append(valid_loss)\n",
        "    epoch_valid_scores.append(valid_scores)\n",
        "    \n",
        "    if(valid_loss == min(epoch_valid_losses)):\n",
        "        torch.save(cnn_encoder.state_dict(), os.path.join(save_model_path, 'cnn_encoder_best.pth'))  # save spatial_encoder\n",
        "        torch.save(rnn_decoder.state_dict(), os.path.join(save_model_path, 'rnn_decoder_best.pth'))  # save motion_encoder\n",
        "        torch.save(optimizer.state_dict(), os.path.join(save_model_path, 'optimizer_epoch.pth'))      # save optimizer\n",
        "        print(\"Epoch {} model saved!\".format(epoch + 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WYnf6LLX2pY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_set = Dataset_CRNN(test_data_path, test_list, test_label, selected_frames, transform=transform)\n",
        "test_loader = data.DataLoader(test_set, **params2)\n",
        "\n",
        "train_pred_loader = data.DataLoader(train_set, **params2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYJPDRU9X2pe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn_encoder.load_state_dict(torch.load(os.path.join(save_model_path, 'cnn_encoder_best.pth')))\n",
        "rnn_decoder.load_state_dict(torch.load(os.path.join(save_model_path, 'rnn_decoder_best.pth')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lN6iVvSPX2py",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_y_pred = CRNN_final_prediction([cnn_encoder, rnn_decoder], device, test_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmudXFbiX2p4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_preds = np.zeros((2000,6))\n",
        "k = 0\n",
        "for i in range(len(all_y_pred)):\n",
        "    for j in range(len(all_y_pred[i])):\n",
        "        batch_pred = all_y_pred[i].cpu()\n",
        "        test_preds[k] = batch_pred[j]\n",
        "        k +=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIZWox5TX2p_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(test_preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOB-PcyTX2qF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(test_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8554EbGX2qM",
        "colab_type": "text"
      },
      "source": [
        "# Eval Metrics IMAGE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYweae36X2qO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(6):\n",
        "  print(1 - mean_absolute_error(test_label[:, i], test_preds[:, i]))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}