{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch \n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error, r2_score, f1_score\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.svm import SVR, SVC\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.device(0)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_Loader(data.Dataset):\n",
    "    def __init__(self, data_path, folders, labels, transform=None):\n",
    "        self.data_path = data_path\n",
    "        self.labels = labels\n",
    "        self.folders = folders\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.folders)\n",
    "\n",
    "    def read_images(self, path, selected_folder, use_transform):\n",
    "        X = []\n",
    "\n",
    "        for i in range(0,15):        \n",
    "            image = Image.open(path+selected_folder+\"/frame\"+str(i+1)+\".jpg\")\n",
    "        \n",
    "            if use_transform is not None:\n",
    "                image = use_transform(image)\n",
    "\n",
    "            X.append(image.squeeze_(0))\n",
    "        X = torch.stack(X, dim=0)\n",
    "        X = X.permute(1,0,2,3)\n",
    "        return X\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        folder = self.folders[index][:-4]\n",
    "        X = self.read_images(self.data_path, folder, self.transform)\n",
    "        y = torch.FloatTensor(self.labels[index])\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D CNN model using Video Resnet 18 pretrained\n",
    "class CNNModel3D(nn.Module):\n",
    "    def __init__(self, out= 6, pretrained=True):\n",
    "        super(CNNModel3D, self).__init__()\n",
    "        \n",
    "        self.VideoResNet = models.video.r3d_18(pretrained)\n",
    "        num_features = self.VideoResNet.fc.in_features\n",
    "\n",
    "        modules = list(self.VideoResNet.fc.children())\n",
    "        modules.extend([nn.Linear(num_features, 128)]) \n",
    "        modules.extend([nn.ReLU(inplace=True)]) \n",
    "        modules.extend([nn.Linear(128, 32)])\n",
    "        modules.extend([nn.ReLU(inplace=True)]) \n",
    "        modules.extend([nn.Linear(32, out)]) \n",
    "        \n",
    "        self.VideoResNet.fc = nn.Sequential(*modules)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x_3d):\n",
    "        \n",
    "        x = self.VideoResNet(x_3d) \n",
    "        x = self.sigmoid(x)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Function\n",
    "def train(model, device, train_loader, optimizer, epoch, log_interval):\n",
    "    model.train()\n",
    "\n",
    "    losses = []\n",
    "    N_count = 0 \n",
    "    for batch_idx, (X, y) in enumerate(train_loader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        N_count += X.size(0)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X) \n",
    "        \n",
    "        criterion = nn.MSELoss(reduction = 'sum')\n",
    "        loss = criterion(output, y)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (batch_idx + 1) % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\t\\tLoss: {:.6f}'.format(\n",
    "                epoch + 1, N_count, len(train_loader.dataset), 100. * (batch_idx + 1) / len(train_loader), loss.item()))\n",
    "\n",
    "    return losses\n",
    "\n",
    "# Evaluation Function\n",
    "def evaluation(model, device, loader):\n",
    "    model.eval()\n",
    "    \n",
    "    loss = 0\n",
    "    all_y = []\n",
    "    all_y_pred = []\n",
    "    score = []\n",
    "    with torch.no_grad():\n",
    "        for (X, y) in loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            output = model(X)\n",
    "            \n",
    "            criterion = nn.MSELoss(reduction = 'sum')\n",
    "            loss = criterion(output, y)\n",
    "            loss += loss.item() \n",
    "            \n",
    "            # collect all y and y_pred in all batches\n",
    "            all_y.extend(y.cpu().detach().numpy())\n",
    "            all_y_pred.extend(output.cpu().detach().numpy())\n",
    "\n",
    "    loss /= len(loader.dataset)\n",
    "    \n",
    "    all_y = np.asarray(all_y)\n",
    "    all_y_pred = np.asarray(all_y_pred)\n",
    "    \n",
    "    for i in range(all_y.shape[1]):\n",
    "        score.extend([1 - mean_absolute_error(all_y[:,i], all_y_pred[:,i])])\n",
    "\n",
    "    return loss.cpu().detach().numpy(), np.asarray(score), all_y, all_y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Path\n",
    "training_data_path = \"/home/ramsub/first-impressions/data/image_data/training_data/\"    \n",
    "validation_data_path = \"/home/ramsub/first-impressions/data/image_data/validation_data/\"\n",
    "test_data_path = \"/home/ramsub/first-impressions/data/image_data/test_data/\"\n",
    "save_model_path = \"./saved_models/\"\n",
    "\n",
    "#Read CSV files\n",
    "aud_train = pd.read_csv('../audio/pickle_files/training_df_all.csv')\n",
    "aud_test = pd.read_csv('../audio/pickle_files/test_df_all.csv')\n",
    "aud_val = pd.read_csv('../audio/pickle_files/validation_df_all.csv')\n",
    "\n",
    "labels = ['interview_score', 'openness', 'conscientiousness', 'extraversion', 'agreeableness', 'neuroticism']\n",
    "\n",
    "train_label = aud_train[labels].values\n",
    "train_list = aud_train['video_id'].values\n",
    "\n",
    "test_label = aud_test[labels].values\n",
    "test_list = aud_test['video_id'].values\n",
    "\n",
    "val_label = aud_val[labels].values\n",
    "val_list = aud_val['video_id'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the CNN Model params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "img_size = 112\n",
    "epochs = 20\n",
    "batch_size = 4\n",
    "learning_rate = 1e-4\n",
    "l_decay = 5e-4\n",
    "log_interval = 25 \n",
    "\n",
    "use_cuda = torch.cuda.is_available()                   # check if GPU exists\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")   # use CPU or GPU\n",
    "print(device)\n",
    "\n",
    "train_params = {'batch_size': batch_size, 'shuffle': True, 'num_workers': 0, 'pin_memory': True} if use_cuda else {}\n",
    "test_params = {'batch_size': batch_size, 'shuffle': False, 'num_workers': 0, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize([img_size, img_size]),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.43216, 0.394666, 0.37645], std=[0.22803, 0.22145, 0.216989]),\n",
    "                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = Dataset_Loader(training_data_path, train_list, train_label, transform=transform)\n",
    "train_loader = data.DataLoader(train_set, **train_params)\n",
    "\n",
    "val_set = Dataset_Loader(validation_data_path, val_list, val_label, transform=transform)\n",
    "val_loader = data.DataLoader(val_set, **test_params)\n",
    "\n",
    "test_set = Dataset_Loader(test_data_path, test_list, test_label, transform=transform)\n",
    "test_loader = data.DataLoader(test_set, **test_params)\n",
    "\n",
    "model = CNNModel3D().to(device)\n",
    "optimizer = torch.optim.Adam(model.VideoResNet.parameters(), lr=learning_rate)\n",
    "\n",
    "val_losses = []\n",
    "val_scores = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    train(model, device, train_loader, optimizer, epoch, log_interval)    \n",
    "    \n",
    "    epoch_val_loss, epoch_val_score, test_annot, test_val_pred = evaluation(model, device, val_loader)\n",
    "    \n",
    "    val_losses.append(epoch_val_loss)    \n",
    "    val_scores.append(epoch_val_score)\n",
    "    \n",
    "    if min(val_losses) == epoch_val_loss:\n",
    "        torch.save(model.state_dict(), os.path.join(save_model_path, 'resnet3d_model_trained.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing loss: 0.0002155\n",
      " Interview: 0.9140\n",
      " openness: 0.9089\n",
      " conscientiousness: 0.9148\n",
      " extraversion: 0.9086\n",
      " agreeableness: 0.9096\n",
      " neuroticism: 0.9057\n"
     ]
    }
   ],
   "source": [
    "saved_model_t = CNNModel3D().to(device)\n",
    "saved_model_t.load_state_dict(torch.load(os.path.join(save_model_path, 'resnet3d_model_trained.pth')))\n",
    "\n",
    "test_loss, test_score, test_annot, test_annot_pred = evaluation(saved_model_t, device, test_loader)\n",
    "print('\\nTesting loss: {:.7f}\\n Interview: {:.4f}\\n openness: {:.4f}\\n conscientiousness: {:.4f}\\n extraversion: {:.4f}\\n agreeableness: {:.4f}\\n neuroticism: {:.4f}'.format(test_loss, test_score[0],test_score[1],test_score[2],test_score[3],test_score[4],test_score[5]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
